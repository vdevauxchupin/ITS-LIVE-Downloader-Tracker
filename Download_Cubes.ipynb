{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e54115a3-ecaa-4131-bcb3-77f84831f91f",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div>\n",
    "    <h2><center>Global Glacier Velocity Data Downloading</center></h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d2616c",
   "metadata": {},
   "source": [
    "# Setting up a local environment\n",
    "at the terminal:\n",
    ">conda create --name Glaciervel -c conda-forge h5netcdf fiona shapely jupyter netcdf4 psutil h5py zarr matplotlib gdal xarray  boto3 pyproj ipympl ipyleaflet s3fs geopandas rasterio seaborn markdown\n",
    "\n",
    "activate newly created environment:\n",
    "> conda activate Glaciervel\n",
    "\n",
    "start jupyter in browser\n",
    "> jupyter notebook\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68c09a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the path for essential python scripts\n",
    "\n",
    "import os\n",
    "import sys\n",
    "path =  os.getcwd()\n",
    "# Avoid Windows users to have issues with how paths are written\n",
    "path = path.replace('\\\\','/')\n",
    "\n",
    "# Import python scripts from scripts folder\n",
    "sys.path.append(path + '/scripts')\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "330a2f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the necessary packages\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import markdown\n",
    "from velocity_widget import ITSLIVE\n",
    "matplotlib.rcParams['figure.figsize'] = [9, 5]\n",
    "matplotlib.rcParams[\"figure.autolayout\"] = True\n",
    "velocity_widget = ITSLIVE()\n",
    "plt.close()\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import time\n",
    "from pyproj import Transformer\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry.polygon import Polygon\n",
    "import geopandas as gpd\n",
    "from ipywidgets import widgets, HTML, Output\n",
    "import numpy as np\n",
    "import math\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ad345d-087a-43e8-bf24-1e0be4ba6565",
   "metadata": {},
   "source": [
    "## Instructions: \n",
    "\n",
    "**First Step**\n",
    "- Select type_dataset: \"Yearly\" or \"Daily\" (\"Daily\" does not necessarily cover every day, just has a higher time resolution). Yearly datasets can be much bigger spatially than the daily ones (because they have only 1 time dimension, while daily dataset might have thousands).\n",
    "- Select a starting date and ending date (format 'yyyy-mm-dd').\n",
    "- If you chose \"Daily\", consider changing the \"threshold\" value. \n",
    "\n",
    "#### How to use the interactive map\n",
    "\n",
    "Run the next two cells, and wait for the map to appear.\n",
    "\n",
    "If you chose \"Yearly\" dataset:\n",
    "- Select an Area Of Interest (AOI) by placing two markers on the map with a right click. Once you have two markers, a blue rectangle representing your AOI will be plotted. If you made a mistake, plot a rectangle then click on \"Clear points\".\n",
    "\n",
    "If you chose \"Daily\" dataset:\n",
    "- Same as for the \"Yearly\" dataset: draw a rectangle with two markers (right click).\n",
    "- Once the rectangle has been drawn, \"sprinkle\" the area with a few points by left double-clicking. A cross will appear for each point. That is because your Area Of Interest (AOI) might be divided into several datacubes. \n",
    "- Click on the \"Get points\".\n",
    "- Once prompted, follow the next step.\n",
    "\n",
    "**To download the data**\n",
    "Click on \"Export data\". Once the message saying it has finished downloading has appeared, you can plot it to see what you downloaded. *Be aware, downloading will take some time*.\n",
    "\n",
    "**To plot the data**\n",
    "Click on the blue 'plot' button when prompted (after exporting the data).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a32b1d9",
   "metadata": {},
   "source": [
    "**MAKE SURE THAT:**\n",
    "- You keep the \"Daily\" datacubes reasonnably small: downloading them takes a lot of memory. I encourage to slice them by date selection. You can also change the threshold set to 40% (meaning it will keep only the time slices with 40% or more data, discard the rest)\n",
    "- All the points you want are in the Area Of Interest (AOI) for which you chose the boundaries' coordinates.\n",
    "- Don't worry if it takes time to download the data, these are big dataset.\n",
    "\n",
    "##### As of the 26/10/22, \"Yearly\" dataset are available from 1985 until 2018 included. If your date range is bigger than that, the code will still run and give an error because the dataset are not available. \"Daily\" dataset are available between 2013 to now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33928f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select the type of dataset you want to download: 'Yearly' or 'Daily'\n",
    "type_dataset = \"Daily\"\n",
    "\n",
    "# Select your date range (careful the datacubes get heavy quickly)\n",
    "sdate = '2020-01-01'\n",
    "edate = '2022-11-01'\n",
    "\n",
    "# Select Threshold quality\n",
    "threshold = 40\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e3794f",
   "metadata": {},
   "source": [
    "#### Run the following Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdc8e3f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db14187eca2146178dbf852a8a9b6c1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GridBox(children=(VBox(children=(Map(center=[57.2, -49.43], controls=(ZoomControl(options=['position', 'zoom_iâ€¦"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[78.88061191129904, 12.505157826768004]\n",
      "click\n",
      "[78.88061191129904, 12.505157826768004]\n",
      "0 (0.12156862745098039, 0.4666666666666667, 0.7058823529411765, 1.0)\n",
      "point added [78.88061191129904, 12.505157826768004]\n",
      "[78.87213369162161, 12.631535174431667]\n",
      "click\n",
      "[78.87213369162161, 12.631535174431667]\n",
      "1 (1.0, 0.4980392156862745, 0.054901960784313725, 1.0)\n",
      "point added [78.87213369162161, 12.631535174431667]\n",
      "[78.87319381804906, 12.812859194992596]\n",
      "click\n",
      "[78.87319381804906, 12.812859194992596]\n",
      "2 (0.17254901960784313, 0.6274509803921569, 0.17254901960784313, 1.0)\n",
      "point added [78.87319381804906, 12.812859194992596]\n",
      "[78.96083753465466, 12.669997845459767]\n",
      "click\n",
      "[78.96083753465466, 12.669997845459767]\n",
      "3 (0.8392156862745098, 0.15294117647058825, 0.1568627450980392, 1.0)\n",
      "point added [78.96083753465466, 12.669997845459767]\n",
      "[78.99444548464474, 12.648019176300874]\n",
      "click\n",
      "[78.99444548464474, 12.648019176300874]\n",
      "4 (0.5803921568627451, 0.403921568627451, 0.7411764705882353, 1.0)\n",
      "point added [78.99444548464474, 12.648019176300874]\n",
      "\n",
      "fetching timeseries for point x=     12.51 y=     78.88\n",
      "original xy [12.505157826768004, 78.88061191129904] 4326 maps to datacube (1019023.3248845997, -649060.4983429275) EPSG:3413\n",
      "[12.505157826768004, 78.88061191129904]\n",
      "elapsed time:       5.90 - 6672.1 points per second\n",
      "fetching timeseries for point x=     12.63 y=     78.87\n",
      "original xy [12.631535174431667, 78.87213369162161] 4326 maps to datacube (1021235.2592057282, -647307.4245226249) EPSG:3413\n",
      "[12.631535174431667, 78.87213369162161]\n",
      "elapsed time:       2.73 - 14411.1 points per second\n",
      "fetching timeseries for point x=     12.81 y=     78.87\n",
      "original xy [12.812859194992596, 78.87319381804906] 4326 maps to datacube (1023180.6000552161, -644010.5527965734) EPSG:3413\n"
     ]
    }
   ],
   "source": [
    "   \n",
    "dates_range = widgets.SelectionRangeSlider(\n",
    "    options=[i for i in range(546)],\n",
    "    index=(1, 120),\n",
    "    continuous_update=False,\n",
    "    description='Interval (days): ',\n",
    "    orientation='horizontal',\n",
    "    layout={'width': '90%',\n",
    "            'display': 'flex'},\n",
    "    style={'description_width': 'initial'})\n",
    "\n",
    "variables =  widgets.Dropdown(\n",
    "    options=['v', 'v_error', 'vx', 'vy'],\n",
    "    description='Variable: ',\n",
    "    disabled=False,\n",
    "    value='v',\n",
    "    layout={'width': '20%',\n",
    "            'display': 'flex'},\n",
    "    style={'description_width': 'initial'})\n",
    "\n",
    "plot_type =  widgets.Dropdown(\n",
    "    options=['location', 'satellite'],\n",
    "    description='Plot By: ',\n",
    "    disabled=False,\n",
    "    value='location',\n",
    "    layout={'width': '20%',\n",
    "            'display': 'flex'},\n",
    "    style={'description_width': 'initial'})\n",
    "\n",
    "plot_button =  widgets.Button(\n",
    "    description='Plot',\n",
    "    button_style='primary',\n",
    "    icon='line-chart',\n",
    "    style={'description_width': 'initial'})\n",
    "\n",
    "get_points =  widgets.Button(\n",
    "    description='Get points',\n",
    "    button_style='primary',\n",
    "    icon='line-chart',\n",
    "    style={'description_width': 'initial'})\n",
    "\n",
    "clear_button =  widgets.Button(\n",
    "    description='Clear Points',\n",
    "    # button_style='warning',\n",
    "    icon=\"trash\",\n",
    "    style={'description_width': 'initial'})\n",
    "\n",
    "latitude = widgets.BoundedFloatText(\n",
    "    value=0.0,\n",
    "    min=-90.0,\n",
    "    max=90.0,\n",
    "    step=0.1,\n",
    "    description='Lat: ',\n",
    "    disabled=False,\n",
    "    style={'description_width': 'initial'},\n",
    "    layout={'width': '20%',\n",
    "            'display': 'flex'},\n",
    ")\n",
    "\n",
    "longitude = widgets.BoundedFloatText(\n",
    "    value=0.0,\n",
    "    min=-180.0,\n",
    "    max=180.0,\n",
    "    step=0.1,\n",
    "    description='Lon: ',\n",
    "    disabled=False,\n",
    "    style={'description_width': 'initial'},\n",
    "    layout={'width': '20%',\n",
    "            'display': 'flex'},\n",
    ")\n",
    "\n",
    "add_button =  widgets.Button(\n",
    "    description='Add Point',\n",
    "    # button_style='info',\n",
    "    icon=\"map-marker\",\n",
    "    style={'description_width': 'initial'})\n",
    "\n",
    "include_running_mean =  widgets.Checkbox(\n",
    "            value=False,\n",
    "            description=\"Include Running Mean\",\n",
    "            style={'description_width': 'initial'},\n",
    "            disabled=False,\n",
    "            indent=False,\n",
    "            tooltip=\"Plot running mean through each time series\",\n",
    "            layout=widgets.Layout(width=\"25%\"),\n",
    "        )\n",
    "\n",
    "export_button = widgets.Button(\n",
    "    description='Export Data',\n",
    "    # button_style='info',\n",
    "    icon=\"file-export\",\n",
    "    style={'description_width': 'initial'})\n",
    "\n",
    "data_link = widgets.HTML(\n",
    "    value=\"<br>\"\n",
    ")\n",
    "\n",
    "# If this congiguration changes we need to rerun the cell.\n",
    "config = { \n",
    "    \"plot\": \"v\", # or other ITS_LIVE variables: vx, vy ...\n",
    "    \"min_separation_days\": 1,\n",
    "    \"max_separation_days\": 90,\n",
    "    \"color_by\": \"location\", # valid values: satellite, points\n",
    "    \"verbose\": True, # print operations\n",
    "    \"runnig_mean\": True,\n",
    "    \"coords\": {\n",
    "        \"latitude\": latitude,\n",
    "        \"longitude\": longitude\n",
    "    },\n",
    "    \"data_link\": data_link\n",
    "}\n",
    "\n",
    "\n",
    "def downloader(whatever):\n",
    "    print('Downloading...')\n",
    "    global pathsave\n",
    "    ######### YEARLY DATASET DOWNLOAD ########\n",
    "    if type_dataset == 'Yearly':\n",
    "\n",
    "            # Create list of years for the date range chosen earlier\n",
    "            list_years = np.arange(int(sdate.split('-')[0]), int(edate.split('-')[0])+1)\n",
    "\n",
    "            # Create path to the files\n",
    "            pathsave = velocity_widget.path_yearly_datacubes\n",
    "            os.makedirs(pathsave, exist_ok = True)\n",
    "            \n",
    "\n",
    "\n",
    "            for Y in range(len(list_years)):\n",
    "\n",
    "                    # Generate URL for the nc file\n",
    "                    url = f'{velocity_widget.url_region[0]}{int(list_years[Y])}.nc#mode=bytes'\n",
    "\n",
    "                    # Load datacube according to prerequisites (time, space and variables)\n",
    "                    start = time.time()\n",
    "                    xrds = xr.open_dataset(url\n",
    "                                            ).sel(x=slice(velocity_widget.xmin_proj, velocity_widget.xmax_proj),\n",
    "                                                y=slice(velocity_widget.ymax_proj, velocity_widget.ymin_proj)).load()\n",
    "\n",
    "                    print(f\"downloaded {list_years[Y]} spatial slice {time.time()-start:8.1f} seconds\")\n",
    "                    xrds.to_netcdf(f\"{pathsave}{list_years[Y]}.nc\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ######## DAILY DATASET DOWNLOAD ########\n",
    "    else:\n",
    "\n",
    "            # Create path to the files\n",
    "            pathsave = velocity_widget.path_daily_datacubes\n",
    "            os.makedirs(pathsave, exist_ok = True)\n",
    "\n",
    "            # Get the cube address\n",
    "            cubes = velocity_widget.dct.addresses\n",
    "            cubes = [*set(cubes)]\n",
    "\n",
    "            # List of variables to drop for the download (we drop everything but the variables written below)\n",
    "            variables_drop = [ele for ele in list(\n",
    "                    xr.open_dataset(cubes[0], engine='zarr').variables\n",
    "                    ) if ele not in ['mid_date','x','y','acquisition_date_img1', 'acquisition_date_img2', 'date_center', 'date_dt', 'satellite_img1','satellite_img2', 'v','vx','vy','roi_valid_percentage']\n",
    "            ]\n",
    "\n",
    "            \n",
    "            for n in range(len(cubes)):\n",
    "\n",
    "                    # Get the cube's URL\n",
    "                    url = cubes[n]\n",
    "\n",
    "                    # Load indices of slices above the quality threshold\n",
    "                    valid = xr.open_dataset(cubes[n], engine='zarr').roi_valid_percentage.values\n",
    "\n",
    "                    # Grab the time values\n",
    "                    t = xr.open_dataset(cubes[n], engine='zarr').mid_date.values\n",
    "\n",
    "                    # Create a time mask, based on the validity of layers and the custom date-range\n",
    "                    t_mask = np.logical_and(valid>threshold, np.logical_and(t>np.datetime64(sdate), t<np.datetime64(edate)))\n",
    "                    \n",
    "                    # Load datacube according to prerequisites (time, space and variables)\n",
    "                    start = time.time()\n",
    "                    xrds = xr.open_dataset(url,\n",
    "                                            engine='zarr',\n",
    "                                            drop_variables=variables_drop\n",
    "                                            ).sel(mid_date=t_mask,\n",
    "                                                x=slice(velocity_widget.xmin_proj, velocity_widget.xmax_proj),\n",
    "                                                y=slice(velocity_widget.ymax_proj, velocity_widget.ymin_proj)).load()\n",
    "\n",
    "                    print(f\"downloaded {cubes[n].split('/')[-1].split('.')[0]} spatial slice {time.time()-start:8.1f} seconds\")\n",
    "                    xrds.to_netcdf(f\"{pathsave}{cubes[n].split('/')[-1].split('.')[0]}_{sdate}_{edate}.nc\")\n",
    "    print('Done ! You can hit \"plot\" now')\n",
    "\n",
    "def plotter(whatever):\n",
    "    list_files = glob.glob(f'{pathsave}*.nc')\n",
    "\n",
    "    fig, ax = plt.subplots(len(list_files), figsize=(10,10*len(list_files)))\n",
    "\n",
    "    if len(list_files) == 1:\n",
    "        if type_dataset == \"Yearly\":\n",
    "            ax.pcolormesh(xr.open_dataset(list_files[0]).x.values,xr.open_dataset(list_files[0]).y.values,xr.open_dataset(list_files[0]).v.values)\n",
    "        else:\n",
    "            ax.pcolormesh(xr.open_dataset(list_files[0]).x.values,xr.open_dataset(list_files[0]).y.values,np.nanmean(xr.open_dataset(list_files[0]).v.values,axis = 0))\n",
    "    else:\n",
    "        if type_dataset == \"Yearly\":\n",
    "            for i in range(len(list_files)):\n",
    "                ax[i].pcolormesh(xr.open_dataset(list_files[i]).x.values,xr.open_dataset(list_files[i]).y.values,xr.open_dataset(list_files[i]).v.values)\n",
    "        else:\n",
    "            for i in range(len(list_files)):\n",
    "                ax[i].pcolormesh(xr.open_dataset(list_files[i]).x.values,xr.open_dataset(list_files[i]).y.values,np.nanmean(xr.open_dataset(list_files[i]).v.values,axis = 0))\n",
    "\n",
    "\n",
    "def update_variable(change):\n",
    "        if change['type'] == 'change' and change['name'] == 'value':\n",
    "            config[\"plot\"] = variables.value\n",
    "            velocity_widget.set_config(config)\n",
    "            velocity_widget.plot_time_series()\n",
    "            \n",
    "def update_range(change):\n",
    "        if change['type'] == 'change' and change['name'] == 'value':\n",
    "            start, end = change['new']\n",
    "            config[\"min_separation_days\"] = start\n",
    "            config[\"max_separation_days\"] = end\n",
    "            velocity_widget.set_config(config)\n",
    "            velocity_widget.plot_time_series()\n",
    "            \n",
    "def update_plottype(change):\n",
    "        if change['type'] == 'change' and change['name'] == 'value':\n",
    "            config[\"color_by\"] = plot_type.value\n",
    "            velocity_widget.set_config(config)\n",
    "            velocity_widget.plot_time_series()\n",
    "            \n",
    "def update_mean(change):\n",
    "        if change['type'] == 'change' and change['name'] == 'value':\n",
    "            config[\"running_mean\"] = include_running_mean.value\n",
    "            velocity_widget.set_config(config)\n",
    "            velocity_widget.plot_time_series()\n",
    "            \n",
    "def add_point(event):\n",
    "    coords = (latitude.value, longitude.value)\n",
    "    velocity_widget.add_point(coords)\n",
    "    \n",
    "def export_ts(event):\n",
    "    velocity_widget.export_data()\n",
    "\n",
    "get_points.on_click(velocity_widget.plot_time_series)\n",
    "plot_button.on_click(plotter)\n",
    "clear_button.on_click(velocity_widget.clear_points)\n",
    "\n",
    "export_button.on_click(downloader)\n",
    "\n",
    "\n",
    "add_button.on_click(add_point)\n",
    "dates_range.observe(update_range, 'value')\n",
    "plot_type.observe(update_plottype, 'value')\n",
    "variables.observe(update_variable, 'value')\n",
    "include_running_mean.observe(update_mean, 'value')\n",
    "\n",
    "layout = widgets.Layout(align_items='stretch',\n",
    "                        display='flex',\n",
    "                        flex_flow='row wrap',\n",
    "                        border='none',\n",
    "                        grid_template_columns=\"repeat(auto-fit, minmax(720px, 1fr))\",\n",
    "                        # grid_template_columns='48% 48%',\n",
    "                        width='99%',\n",
    "                        height='100%')\n",
    "\n",
    "velocity_widget.set_config(config)\n",
    "\n",
    "velocity_widget.fig.canvas.capture_scroll = True\n",
    "\n",
    "# We render the widget\n",
    "widgets.GridBox([\n",
    "                widgets.VBox([velocity_widget.map,\n",
    "                            widgets.HBox([latitude, longitude, add_button, clear_button], layout=widgets.Layout(align_items=\"flex-start\",\n",
    "                                                                                                                flex_flow='row wrap'))],\n",
    "                            \n",
    "                            layout=widgets.Layout(min_width=\"100%\",\n",
    "                                                    display=\"flex\",\n",
    "                                                    # height=\"100%\",\n",
    "                                                    # max_height=\"100%\",\n",
    "                                                    max_width=\"100%\")),\n",
    "                widgets.VBox([\n",
    "                            widgets.HBox([get_points, export_button, plot_button, data_link])\n",
    "                            ], layout=widgets.Layout(min_width=\"720px\",\n",
    "                                                        overflow='scroll',\n",
    "                                                        max_width=\"100%\",\n",
    "                                                        display='flex'))],\n",
    "                layout=layout)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474afe06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "2b7814ffd776579197ebe28bd31711c0ecb3137f77c21042d9f4200b395566ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
